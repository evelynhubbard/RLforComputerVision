% CVPR 2022 Paper Template
% based on the CVPR template provided by Ming-Ming Cheng (https://github.com/MCG-NKU/CVPR_Template)
% modified and extended by Stefan Roth (stefan.roth@NOSPAMtu-darmstadt.de)

\documentclass[10pt,twocolumn,letterpaper]{article}

%%%%%%%%% PAPER TYPE  - PLEASE UPDATE FOR FINAL VERSION
\usepackage{cvpr}      % To produce the REVIEW version
%\usepackage{cvpr}              % To produce the CAMERA-READY version
%\usepackage[pagenumbers]{cvpr} % To force page numbers, e.g. for an arXiv version


% Include other packages here, before hyperref.
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{booktabs}
\usepackage{breqn}
\usepackage{soul}
\usepackage{fancyhdr}

% It is strongly recommended to use hyperref, especially for the review version.
% hyperref with option pagebackref eases the reviewers' job.
% Please disable hyperref *only* if you encounter grave issues, e.g. with the
% file validation for the camera-ready version.
%
% If you comment hyperref and then uncomment it, you should delete
% ReviewTempalte.aux before re-running LaTeX.
% (Or just hit 'q' on the first LaTeX run, let it finish, and you
%  should be clear).
\usepackage[pagebackref,breaklinks,colorlinks]{hyperref}


% Support for easy cross-referencing
\usepackage[capitalize]{cleveref}
\crefname{section}{Sec.}{Secs.}
\Crefname{section}{Section}{Sections}
\Crefname{table}{Table}{Tables}
\crefname{table}{Tab.}{Tabs.}


% %%%%%%%%% PAPER ID  - PLEASE UPDATE
% \def\cvprPaperID{*****} % *** Enter the CVPR Paper ID here
% \def\confName{CVPR}
% \def\confYear{2022}
\fancypagestyle{regular}{
\fancyhf{} 
\fancyfoot[C]{\thepage}
\fancyhead[L]{ECSE 626 Final Report} % Left header
\fancyhead[C]{Evelyn Hubbard} % Center header
\fancyhead[R]{December 3rd, 2024} % Right header
\setlength{\headsep}{10.0pt}
\setlength{\headheight}{15pt}
}
\pagestyle{regular}
\fancypagestyle{title}{
\fancyhf{} 
\fancyfoot[C]{\thepage}
\fancyhead[L]{ECSE 626 Final Report} % Left header
\fancyhead[C]{Evelyn Hubbard} % Center header
\fancyhead[R]{December 3rd, 2024} % Right header
\setlength{\headsep}{0.0pt}
\setlength{\headheight}{15pt}
}
\begin{document}

%%%%%%%%% TITLE - PLEASE UPDATE
\title{Image Classification by Reinforcement Learning with Tow-State Q-Learning\cite{hafizImageClassificationReinforcement2022}}
\author{Paper by: Abdul Mueed Hafiz}

\maketitle


% \thispagestyle{plain}
% \fancyhf{} 
% \fancyfoot[C]{\thepage}
% \pagestyle{plain}
% Institution1\\
% % For a paper whose authors are all at the same institution,
% % omit the following lines up until the closing ``}''.
% % Additional authors and addresses can be added with ``\and'',
% % just like the second author.
% % To save space, use either the email address or home page, not both
% \and
% }

%%%%%%%%% ABSTRACT
\begin{abstract}
\end{abstract}
\thispagestyle{title}

\section{Introduction}\label{sec:intro}
Reinforcement Learning (RL) is a branch of machine learning where an agent learns the best policy by interacting with the environment and receiving feedback \cite{suttonReinforcementLearningIntroduction1992}. Convolutional Neural Networks (CNNs) are often used to extract feature maps from images, which can be used for image classification. CNNs can struggle with 'hard to class' images and prior work has explored the integration of RL with CNNs to improve image classification accuracy by making the learning process active \cite{leDeepReinforcementLearning2022}. The work of Hafiz et al. introduces an approach which combines CNNs with a simple two-state Q-Learning algorithm to improve classification. The control actions for this algorithm are rotations and translations, that help to clarify misclassified images \cite{hafizImageClassificationReinforcement2022}. 

The paper presents a method where a pre-trained CNN, such as ResNet50 or InceptionV3, is used to extract feature maps from an image. Classification, using an also pre-trained classification structure, is performed on these maps. Before being fed into the classification structure, RL is used to improve the classification performance. The RL algorithm sends a more easily identifiable image by applying a learned best transformation. The simple RL algorithm takes place on a two-state space and three-action space and updates a Q-table N times to learn the best transformation to apply to each image in each state. After the transformation (or lack of) occurs, the updated feature maps are reclassified. The agent's reward (value function) is based on a standard deviation metric which measures how the classification confidence changes after the transformation [1].

For this project, I will reproduce the core aspects of the algorithm as described in the paper. The paper used several datasets. I will aim to use samples from the 'Cats and Dogs' dataset for classification experiments \cite{parkhiCatsDogs2012}. I will implement the Q-learning algorithm from scratch and use pre-trained CNNs to extract feature maps, as done in the original work. For classification, I will also use code from pre-trained neural networks. These pre-trained models will be sourced from available deep-learning frameworks/libraries. The results will measure classification accuracy before and after applying learned transformations, which will display the improvement from the RL model.

\section{Literature Review and Contribution of \cite{hafizImageClassificationReinforcement2022}}
\section{Background}
%RL and Q-Learning background

\section{Method}
\subsection{Model Architecture}
\subsection{Q-Learning Algorithm}

\section{Implementation}
\section{Results}
\section{Discussion}
\newpage
%%%%%%%%% REFERENCES
{\small
\bibliographystyle{ieee_fullname}
\bibliography{FinalProjectReferences}

}

\end{document}
